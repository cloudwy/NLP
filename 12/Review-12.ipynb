{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import stanfordcorenlp\n",
    "import math\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"./sqlResult_1558435.csv\"\n",
    "data = pd.read_csv(data_source,encoding='gb18030')\n",
    "data = data.fillna('')  #缺失数据填充\n",
    "content = data['content'].tolist()\n",
    "def cut(string): return ' '.join(jieba.cut(string))\n",
    "def token(string): return re.findall(r'[\\d|\\w]+',string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\wy\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.462 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "news_content = [token(n) for n in content]\n",
    "news_content = [''.join(n) for n in news_content]\n",
    "news_content = [cut(n) for n in news_content]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term frequency: $tf_{t,d} = log_{10} count(t,d)+1$  \n",
    "Inverse document frequency: $idf_{t} = log_{10} (N/df_{t})$  \n",
    "TF-idfweighted value: $w_{t,d} = tf_{t,d} x idf_{t}$   \n",
    "\n",
    "N - 文档总数  \n",
    "df_t - 出现t这个词的文档数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_frequency(word):\n",
    "    return sum(1 for n in news_content if word in n)\n",
    "\n",
    "def idf(word):\n",
    "    return math.log10(len(news_content)/document_frequency(word))+1\n",
    "\n",
    "def tf(word,document):\n",
    "    words = document.split()\n",
    "    return sum(1 for w in words if w==word)\n",
    "\n",
    "def tf_idf(word,document):\n",
    "    return tf(word,document)*idf(word)\n",
    "\n",
    "def get_keywords_of_a_document(document):\n",
    "    words = set(document.split())\n",
    "    tfidf = [\n",
    "        (w,tf_idf(w,document)) for w in words\n",
    "    ]\n",
    "    tfidf = sorted(tfidf,key=lambda x:x[1],reverse=True)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('骁龙', 18.28860032832347),\n",
       " ('Windows10', 15.14781401040159),\n",
       " ('桌面', 11.674990450316585),\n",
       " ('的', 8.84117289241158),\n",
       " ('高通', 8.392972936239964)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keywords_of_a_document(news_content[1])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "sample_num = 50000 \n",
    "sub_samples = news_content[:sample_num]\n",
    "X = vectorizer.fit_transform(sub_samples)  #X为50000x10000的稀疏矩阵,10000表示word的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997881303720474"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_1,document_2 = random.randint(0,1000),random.randint(0,1000)\n",
    "vector_of_document_1 = X[document_1].toarray()[0]\n",
    "vector_of_document_2 = X[document_2].toarray()[0]\n",
    "def distance(v1,v2): return cosine(v1,v2)\n",
    "distance(vector_of_document_1,vector_of_document_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import jieba.posseg as jp,jieba  #jp用于词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = ('n', 'nr', 'ns', 'nt', 'eng', 'v', 'd')\n",
    "data = pd.read_csv(data_source,encoding='gb18030')\n",
    "news = data[\"content\"][:100]  #取前100个\n",
    "\n",
    "#获取停用词表\n",
    "stop_words = []\n",
    "with open('./baidu_stopwords.txt',encoding='utf-8') as f:\n",
    "    for word in f.readlines():\n",
    "        stop_words.append(word.strip())\n",
    "\n",
    "#获取词语列表        \n",
    "words_ls = []\n",
    "for text in news:\n",
    "    words = [w.word for w in jp.cut(text) if w.flag in flags and w.word not in stop_words]\n",
    "    words_ls.append(words)\n",
    "\n",
    "#为语料库的词分配编号\n",
    "dictionary = corpora.Dictionary(words_ls)\n",
    "corpus = [dictionary.doc2bow(words) for words in words_ls]\n",
    "\n",
    "#lda\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus,id2word=dictionary,num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x239cf110390>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(445, 0.007042604),\n",
       " (401, 0.004634682),\n",
       " (154, 0.004621647),\n",
       " (80, 0.0041359016),\n",
       " (372, 0.0040862425),\n",
       " (140, 0.0040819966),\n",
       " (151, 0.0037752644),\n",
       " (131, 0.0034634636),\n",
       " (885, 0.0029189899),\n",
       " (212, 0.00283667)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_topic_terms(0,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.0003043753), (3, 0.00012307003)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_term_topics(0,minimum_probability=1e-4)  #0为词id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.007*\"市场\" + 0.005*\"中国\" + 0.005*\"会\" + 0.004*\"还\" + 0.004*\"都\" + 0.004*\"不\" + 0.004*\"人\" + 0.003*\"记者\" + 0.003*\"电影\" + 0.003*\"女子\"')\n",
      "(1, '0.005*\"内容\" + 0.005*\"不\" + 0.005*\"会\" + 0.005*\"都\" + 0.004*\"市场\" + 0.004*\"人\" + 0.004*\"记者\" + 0.004*\"还\" + 0.003*\"乐视\" + 0.003*\"中国\"')\n",
      "(2, '0.006*\"企业\" + 0.006*\"都\" + 0.005*\"手机\" + 0.005*\"会\" + 0.004*\"跨境\" + 0.004*\"乐视\" + 0.004*\"不\" + 0.004*\"人\" + 0.004*\"市场\" + 0.004*\"还\"')\n",
      "(3, '0.005*\"都\" + 0.005*\"不\" + 0.005*\"中国\" + 0.004*\"市场\" + 0.004*\"会\" + 0.004*\"人\" + 0.004*\"还\" + 0.004*\"冰架\" + 0.003*\"摄像头\" + 0.003*\"乐视\"')\n",
      "(4, '0.006*\"市场\" + 0.004*\"中国\" + 0.004*\"企业\" + 0.004*\"都\" + 0.004*\"配送\" + 0.004*\"冰架\" + 0.004*\"人\" + 0.004*\"跨境\" + 0.004*\"还\" + 0.003*\"相关\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in lda.print_topics(num_words=10):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
