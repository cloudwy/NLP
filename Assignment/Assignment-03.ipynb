{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-03 First Step of Machine Learning: Model and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同学们，今天我们的学习了基本的机器学习概念，相比你已经对机器学习的这些方法有一个基本的认识了。值得说明的是，机器学习不仅仅是一系列方法，更重要的是一种思维体系，即：依据以往的、现有的数据，构建某种方法来解决未见过的问题。而且决策树，贝叶斯只是实现这个目标的一个方法，包括之后的神经网络。很有可能有一天，神经网络也会被淘汰，但是重要的是我们要理解机器学习的目标，就是尽可能的自动化解决未知的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1571556399207&di=4a97dc15ad08dd49d3748d1edf6109b3&imgtype=0&src=http%3A%2F%2Fc.hiphotos.baidu.com%2Fzhidao%2Fwh%3D450%2C600%2Fsign%3Dae742c6aedcd7b89e93932873a146e91%2F5d6034a85edf8db1b16050c40223dd54574e74c7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-1 Programming Review 编程回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Re-code the Linear-Regression Model using scikit-learning(10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>： \n",
    "> + 是否完成线性回归模型 (4')\n",
    "+ 能够进行预测新数据(3')\n",
    "+ 能够进行可视化操作(3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Complete the unfinished KNN Model using pure python to solve the previous Line-Regression problem. (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>:\n",
    "> + 是否完成了KNN模型 (4')\n",
    "+ 是否能够预测新的数据 (4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Re-code the Decision Tree, which could sort the features by salience. (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否实现了信息熵 (1' )\n",
    "+ 是否实现了最优先特征点的选择(5')\n",
    "+ 是否实现了持续的特征选则(6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Finish the K-Means using 2-D matplotlib (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否完成了KMeans模型，基于scikit-learning (3')\n",
    "+ 是否完成了可视化任务（5'）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-2 Question and Answer 问答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What's the *model*? why  all the models are wrong, but some are useful? (5 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A computer-based model is a computer program that is designed to simulate what might or what did happen in a situation. \"All models are wrong\" that is, every model is wrong because it is a simplification of reality.\"But some are useful\" means the simplification can help us solve a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对模型的理解是否正确,对模型的抽象性是否正确(5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the underfitting and overfitting? List the reasons that could make model overfitting or underfitting. (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting occurs when the model or the algorithm fits the data too well. It shows low variance but high bias.<br>\n",
    "Reason: a small dataset/too many features/too much noise<br>\n",
    "\n",
    "Underfitting occurs when the model cannot capture the underlying trend of the data. It shows high variance,low bias.<br>\n",
    "Reason: too few features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对过拟合和欠拟合的理解是否正确 (3')\n",
    "+ 对欠拟合产生的原因是否理解正确(2')\n",
    "+ 对过拟合产生的原因是否理解正确(5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What's the precision, recall, AUC, F1, F2score. What are they mainly target on? (12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "$$Precision = \\frac{\\sum True\\, positive}{\\sum Predicted\\, condition\\, positive} = \\frac{TP}{TP+FP} $$\n",
    "\n",
    "$$Recall/Sensitivity = \\frac{\\sum True\\,positive}{\\sum Condition\\,positive} = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "$$AUC = the\\,area\\,under\\,the\\,ROC\\,curve$$\n",
    "\n",
    "$$F_{\\beta} = (1+\\beta^{2})·\\frac{Precision·Recall}{(\\beta^{2}·Precision)+Recall}$$\n",
    "\n",
    "$$F_{1} score = 2*\\frac{Precision·Recall}{Precision+Recall}$$\n",
    "\n",
    "$$F_{2} score = 5*\\frac{Precision·Recall}{4·Precision+Recall}$$\n",
    "Precision表示在所有预测为1的样本中，预测正确的概率。<br>\n",
    "Recall表示在所有实际为1的样本中，预测正确的概率。<br>\n",
    "F1 score综合反映了Precision和Recall。<br>\n",
    "ROC曲线是以FP为横轴，TP为纵轴画出的曲线，其下的面积为AUC，如果AUC面积越大，则模型预测效果越好。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对precision, recall, AUC, F1, F2 理解是否正确(6‘)\n",
    "+ 对precision, recall, AUC, F1, F2的使用侧重点是否理解正确 (6’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Based on our course and yourself mind, what's the machine learning?  (8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is a branch of AI that provides systems the ability to automatically learn and improve from experience without being explicitly programmed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点> 开放式问题，是否能说出来机器学习这种思维方式和传统的分析式编程的区别（8'）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. \"正确定义了机器学习模型的评价标准(evaluation)， 问题基本上就已经解决一半\". 这句话是否正确？你是怎么看待的？ (8‘)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评价标准能判断模型学习的优劣程度，选对评价标准即指明了模型正确学习的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点> 开放式问题，主要看能理解评价指标对机器学习模型的重要性."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-03 Programming Practice 编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In our course and previous practice, we complete some importance components of Decision Tree. In this problem, you need to build a **completed** Decision Tree Model. You show finish a `predicate()` function, which accepts three parameters **<gender, income, family_number>**, and outputs the predicated 'bought': 1 or 0.  (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:https://blog.csdn.net/weixin_41059350/article/details/90242277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from icecream import ic\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step1:创建数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {\n",
    "    'gender':['F', 'F', 'F', 'F', 'M', 'M', 'M'],\n",
    "    'income': ['+10', '-10', '+10', '+10', '+10', '+10', '-10'],\n",
    "    'family_number': [1, 1, 2, 1, 1, 1, 2],\n",
    "    'bought': [1, 1, 1, 0, 0, 0, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入数据：dict->DataFrame\n",
    "dataset = pd.DataFrame.from_dict(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'bought'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender', 'income', 'family_number']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset.columns.tolist()\n",
    "labels.remove(target)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step2：计算Entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#信息熵\n",
    "def entropy(elements):\n",
    "    counter = Counter(elements)\n",
    "    probs = [counter[c]/len(elements) for c in set(elements)]\n",
    "    #ic(probs)\n",
    "    return - sum(p * np.log(p) for p in probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step3：选择最优特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_spliter(training_data:pd.DataFrame,target:str)->str:\n",
    "    x_fields = set(training_data.columns.tolist()) - {target}\n",
    "    #ic(x_fields)\n",
    "    spliter = None\n",
    "    min_entropy = float('inf')\n",
    "    \n",
    "    for f in x_fields:\n",
    "        ic(f)\n",
    "        #print('f:',type(f))\n",
    "        values = set(training_data[f])\n",
    "        ic(values)\n",
    "        for v in values:\n",
    "            #print('v:',type(v))\n",
    "            #sub_spliter_1\n",
    "            sub_spliter_1 = training_data[training_data[f]== v][target].tolist()\n",
    "            #ic(sub_spliter_1)\n",
    "            entropy_1 = entropy(sub_spliter_1)\n",
    "            #ic(entropy_1)\n",
    "            #sub_spliter_2\n",
    "            sub_spliter_2 = training_data[training_data[f]!= v][target].tolist()\n",
    "            #ic(sub_spliter_2)\n",
    "            entropy_2 = entropy(sub_spliter_2)\n",
    "            #ic(entropy_2)\n",
    "            #the sum of entropy\n",
    "            entropy_v = entropy_1 + entropy_2\n",
    "            #ic(entropy_v) \n",
    "            #compare\n",
    "            if entropy_v <= min_entropy:\n",
    "                min_entropy = entropy_v\n",
    "                spliter = (f,v)\n",
    "    print('spliter is: {}'.format(spliter))\n",
    "    print('the min entropy is: {}'.format(min_entropy)) \n",
    "    return spliter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| f: 'family_number'\n",
      "ic| values: {1, 2}\n",
      "ic| f: 'income'\n",
      "ic| values: {'-10', '+10'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliter is: ('income', '+10')\n",
      "the min entropy is: 0.6730116670092565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'income'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_spliter(dataset,target='bought')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step4：按照给定特征划分数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(training_data:pd.DataFrame,spliter:str,value):\n",
    "    subset = training_data[training_data[spliter] == value]\n",
    "    return subset.drop(spliter,axis=1) #删除dataFrame的某一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1 = splitDataset(dataset,spliter='family_number',value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  bought\n",
       "0      F       1\n",
       "1      F       1\n",
       "3      F       0\n",
       "4      M       0\n",
       "5      M       0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset1.drop('income',axis=1) #删除某列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender income  bought\n",
       "1      F    -10       1\n",
       "3      F    +10       0\n",
       "4      M    +10       0\n",
       "5      M    +10       0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset1.drop(0,axis=0) #删除某行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step4:多数表决**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def majority(targetList:list):\n",
    "    classCount={}\n",
    "    for v in targetList:\n",
    "        if v not in classCount.keys():\n",
    "            classCount[v]=0\n",
    "        classCount[v]+=1\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注释：\n",
    "\n",
    "    1.dict.items()\n",
    "    作用：是可以将字典中的所有项，以列表方式返回。因为字典是无序的，所以用items方法返回字典的所有项，也是没有顺序的。\n",
    "    2.operator.itemgetter()\n",
    "    operator模块提供的itemgetter函数用于获取对象的哪些维的数据，参数为一些序号.\n",
    "    3.sorted()函数，排序\n",
    "    list.sort()是对已经存在的列表进行操作，进而可以改变进行操作的列表；\n",
    "    sorted返回的是一个新的list，而不是在原来的基础上进行的操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>family_number</th>\n",
       "      <th>bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender income  family_number  bought\n",
       "0      F    +10              1       1\n",
       "1      F    -10              1       1\n",
       "3      F    +10              1       0\n",
       "4      M    +10              1       0\n",
       "5      M    +10              1       0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = splitDataset(dataset,spliter='family_number',value=1)\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetList = subset['bought'].tolist()\n",
    "targetList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority(targetList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step5:创建树**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender', 'income', 'family_number']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset.columns.tolist()\n",
    "labels.remove(target)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(training_data:pd.DataFrame,labels:list,target:str):\n",
    "    ic(labels)\n",
    "    targetList = training_data[target].tolist() #等于classList\n",
    "    labels1 = labels[:]\n",
    "    #类别完全相同则停止划分\n",
    "    if targetList.count(targetList[0]) == len(targetList):\n",
    "        return targetList[0]\n",
    "    #遍历完所有特征时返回出现次数最多的类别\n",
    "    if training_data.shape[1] == 1:\n",
    "        return majority(targetList)\n",
    "    bestFeat = bestFeat = best_spliter(training_data,target)\n",
    "    tree = {bestFeat:{}}\n",
    "    labels1.remove(bestFeat)\n",
    "    #得到bestFeat的所有制\n",
    "    featValue = training_data[bestFeat].tolist()\n",
    "    uniqueVal = set(featValue)\n",
    "    for v in uniqueVal:\n",
    "        sublabels = labels1\n",
    "        #运用递归方法\n",
    "        tree[bestFeat][v] = createTree(splitDataset(training_data,bestFeat,v),sublabels,target)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| labels: ['gender', 'income', 'family_number']\n",
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| f: 'family_number'\n",
      "ic| values: {1, 2}\n",
      "ic| f: 'income'\n",
      "ic| values: {'-10', '+10'}\n",
      "ic| labels: ['gender', 'family_number']\n",
      "ic| labels: ['gender', 'family_number']\n",
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| f: 'family_number'\n",
      "ic| values: {1, 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliter is: ('income', '+10')\n",
      "the min entropy is: 0.6730116670092565\n",
      "spliter is: ('family_number', 2)\n",
      "the min entropy is: 0.5623351446188083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| labels: ['gender']\n",
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| labels: []\n",
      "ic| labels: []\n",
      "ic| labels: ['gender']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliter is: ('gender', 'M')\n",
      "the min entropy is: 0.6931471805599453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'income': {'-10': 1,\n",
       "  '+10': {'family_number': {1: {'gender': {'F': 1, 'M': 0}}, 2: 1}}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = createTree(dataset,labels,'bought')\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['income'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[tree.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'family_number': {1: {'gender': {'F': 1, 'M': 0}}, 2: 1}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree['income']['+10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step5:使用决策树分类**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key1': '1', 'key2': '2', 'key3': '3'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = ['key1','key2','key3']\n",
    "list2 = ['1','2','3']\n",
    "dict(zip(list1,list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(training_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree,labels,sample):\n",
    "    testSample = dict(zip(labels,sample))\n",
    "    #ic(testSample)\n",
    "    Feat = list(tree.keys())[0]\n",
    "    #ic(Feat)\n",
    "    #print(type(tree[Feat][testSample[Feat]]))\n",
    "    if isinstance(tree[Feat][testSample[Feat]],dict):\n",
    "        decision(tree[Feat][testSample[Feat]],labels,sample)\n",
    "    else:\n",
    "        print(tree[Feat][testSample[Feat]])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#<gender, income, family_number>\n",
    "sample = ('F','+10',1)\n",
    "predict(tree,labels,sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "sample = ('M','+10',1)\n",
    "predict(tree,labels,sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否将之前的决策树模型的部分进行合并组装， predicate函数能够顺利运行(8')\n",
    "+ 是够能够输入未曾见过的X变量，例如gender, income, family_number 分别是： <M, -10, 1>, 模型能够预测出结果 (12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 将上一节课(第二节课)的线性回归问题中的Loss函数改成\"绝对值\"，并且改变其偏导的求值方式，观察其结果的变化。(19 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=dataset['data'],dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rm = x[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step1:Assume that the target funciton is a linear function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target function\n",
    "def price(rm, k, b):\n",
    "    return k * rm + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step2:Loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$loss = \\frac{1}{n} \\sum{(\\left|y_i - \\hat{y_i}\\right|)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y,y_hat):\n",
    "    return sum(abs(y_i - y_hat_i) for y_i, y_hat_i in zip(list(y),list(y_hat)))/len(list(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step3:Partial derivatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial{loss}}{\\partial{k}} = -\\frac{2}{n}\\sum(y_i - \\hat{y_i})x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial{loss}}{\\partial{b}} = -\\frac{2}{n}\\sum(y_i - \\hat{y_i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define partial derivative \n",
    "def partial_derivative_k(x, y, y_hat): \n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for x_i, y_i, y_hat_i in zip(list(x),list(y),list(y_hat)):\n",
    "        gradient += (y_i-y_hat_i) * x_i\n",
    "    return -2/n * gradient\n",
    "\n",
    "def partial_derivative_b(y, y_hat):\n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for y_i, y_hat_i in zip(list(y),list(y_hat)):\n",
    "        gradient += (y_i-y_hat_i)\n",
    "    return -2 / n * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step4:训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-93.41483781633306\n",
      "-20.971237364744113\n",
      "Iteration 0, the loss is 630.5821457182709, parameters k is -93.41483781633306 and b is -20.971237364744113\n",
      "Iteration 1, the loss is 578.8743739628034, parameters k is -85.3878621237521 and b is -19.71007307330757\n",
      "Iteration 2, the loss is 531.4042927496419, parameters k is -78.0187250171541 and b is -18.552324325381964\n",
      "Iteration 3, the loss is 487.82460383709804, parameters k is -71.25351359728018 and b is -17.48951573988268\n",
      "Iteration 4, the loss is 447.8164716726459, parameters k is -65.04273337507134 and b is -16.513866532208485\n",
      "Iteration 5, the loss is 411.0871907445611, parameters k is -59.34094616261919 and b is -15.618233588863195\n",
      "Iteration 6, the loss is 377.3680441048276, parameters k is -54.10643764061967 and b is -14.796059207374073\n",
      "Iteration 7, the loss is 346.4123373959477, parameters k is -49.30091217020375 and b is -14.041323119164417\n",
      "Iteration 8, the loss is 317.9935939982984, parameters k is -44.88921261634317 and b is -13.348498444372522\n",
      "Iteration 9, the loss is 291.9038980934777, parameters k is -40.83906313301735 and b is -12.712511256375926\n",
      "Iteration 10, the loss is 267.95237352122064, parameters k is -37.120833028319595 and b is -12.128703460188971\n",
      "Iteration 11, the loss is 245.96378730100452, parameters k is -33.70731998190456 and b is -11.59279871314653\n",
      "Iteration 12, the loss is 225.7772676014766, parameters k is -30.5735510287635 and b is -11.100871138544521\n",
      "Iteration 13, the loss is 207.24512677819223, parameters k is -27.69659985329499 and b is -10.649316603341568\n",
      "Iteration 14, the loss is 190.23178086882209, parameters k is -25.055419056967384 and b is -10.234826349785184\n",
      "Iteration 15, the loss is 174.61275764070427, parameters k is -22.630686172418223 and b is -9.85436278804754\n",
      "Iteration 16, the loss is 160.27378593346015, parameters k is -20.40466229740683 and b is -9.505137272766131\n",
      "Iteration 17, the loss is 147.1099596341775, parameters k is -18.36106231436508 and b is -9.184589700899211\n",
      "Iteration 18, the loss is 135.02497016867193, parameters k is -16.484935746053175 and b is -8.890369781630856\n",
      "Iteration 19, the loss is 123.93040189362242, parameters k is -14.762557375642798 and b is -8.620319841293512\n",
      "Iteration 20, the loss is 113.7450852345652, parameters k is -13.181326830987743 and b is -8.372459037506268\n",
      "Iteration 21, the loss is 104.39450283720272, parameters k is -11.729676398425749 and b is -8.144968867037138\n",
      "Iteration 22, the loss is 95.81024438734991, parameters k is -10.396986391663447 and b is -7.936179861362732\n",
      "Iteration 23, the loss is 87.92950611089074, parameters k is -9.173507456570695 and b is -7.744559372588032\n",
      "Iteration 24, the loss is 80.69463129201961, parameters k is -8.050289243454563 and b is -7.56870036036625\n",
      "Iteration 25, the loss is 74.05268844812534, parameters k is -7.019114924968703 and b is -7.407311097782211\n",
      "Iteration 26, the loss is 67.95508407518605, parameters k is -6.072441080581399 and b is -7.25920572088596\n",
      "Iteration 27, the loss is 62.35720713046063, parameters k is -5.203342507788105 and b is -7.123295552735589\n",
      "Iteration 28, the loss is 57.218102651459, parameters k is -4.405461556299103 and b is -6.998581138474667\n",
      "Iteration 29, the loss is 52.50017212334073, parameters k is -3.672961614523634 and b is -6.884144933171749\n",
      "Iteration 30, the loss is 48.16889840258415, parameters k is -3.000484408050718 and b is -6.779144588925067\n",
      "Iteration 31, the loss is 44.19259318442575, parameters k is -2.3831107977159736 and b is -6.682806792119899\n",
      "Iteration 32, the loss is 40.54216516650613, parameters k is -1.816324790447272 and b is -6.594421605751047\n",
      "Iteration 33, the loss is 37.19090721257179, parameters k is -1.2959804995872104 and b is -6.513337275418035\n",
      "Iteration 34, the loss is 34.11430095909054, parameters k is -0.8182718129692075 and b is -6.438955460992892\n",
      "Iteration 35, the loss is 31.289837435254313, parameters k is -0.3797045468343451 and b is -6.37072685907471\n",
      "Iteration 36, the loss is 28.69685238399867, parameters k is 0.022929118137121562 and b is -6.308147184204202\n",
      "Iteration 37, the loss is 26.316375079221675, parameters k is 0.39257410570939977 and b is -6.250753479436205\n",
      "Iteration 38, the loss is 24.130989533128417, parameters k is 0.7319339895917675 and b is -6.198120729277762\n",
      "Iteration 39, the loss is 22.124707078271488, parameters k is 1.0434907731862664 and b is -6.149858750211505\n",
      "Iteration 40, the loss is 20.282849392080198, parameters k is 1.3295230482940363 and b is -6.105609336054963\n",
      "Iteration 41, the loss is 18.591941108067765, parameters k is 1.5921226656321057 and b is -6.0650436372708025\n",
      "Iteration 42, the loss is 17.03961122804432, parameters k is 1.8332100391246107 and b is -6.027859755054667\n",
      "Iteration 43, the loss is 15.622660855370857, parameters k is 2.054548195936919 and b is -5.993780532598579\n",
      "Iteration 44, the loss is 14.351793215602585, parameters k is 2.257755675044803 and b is -5.962551527370474\n",
      "Iteration 45, the loss is 13.196587521173086, parameters k is 2.4443183687065044 and b is -5.933939149574762\n",
      "Iteration 46, the loss is 12.168951040373996, parameters k is 2.615600393471674 and b is -5.907728953174608\n",
      "Iteration 47, the loss is 11.247592849162455, parameters k is 2.7728540702610998 and b is -5.883724066972803\n",
      "Iteration 48, the loss is 10.434630148649024, parameters k is 2.91722908653297 and b is -5.861743754272779\n",
      "Iteration 49, the loss is 9.724091998200485, parameters k is 3.0497809075674516 and b is -5.841622090582028\n",
      "Iteration 50, the loss is 9.095093493944045, parameters k is 3.171478498407786 and b is -5.823206749683817\n",
      "Iteration 51, the loss is 8.561281322571569, parameters k is 3.283211412952778 and b is -5.806357889195909\n",
      "Iteration 52, the loss is 8.108469164379194, parameters k is 3.385796302065527 and b is -5.790947127462873\n",
      "Iteration 53, the loss is 7.708496470639783, parameters k is 3.4799828883127044 and b is -5.7768566042967855\n",
      "Iteration 54, the loss is 7.360213667651546, parameters k is 3.566459451046446 and b is -5.763978118694542\n",
      "Iteration 55, the loss is 7.054368986008179, parameters k is 3.645857861958543 and b is -5.752212337223216\n",
      "Iteration 56, the loss is 6.782559510211763, parameters k is 3.718758207947795 and b is -5.741468067281871\n",
      "Iteration 57, the loss is 6.543973610141399, parameters k is 3.7856930351221063 and b is -5.731661589922917\n",
      "Iteration 58, the loss is 6.333630341606564, parameters k is 3.8471512449850813 and b is -5.722716047351822\n",
      "Iteration 59, the loss is 6.152878124466001, parameters k is 3.9035816713122 and b is -5.71456088062405\n",
      "Iteration 60, the loss is 5.995713008164535, parameters k is 3.9553963638855256 and b is -5.70713131342531\n",
      "Iteration 61, the loss is 5.857363642292811, parameters k is 4.002973603111245 and b is -5.7003678781584\n",
      "Iteration 62, the loss is 5.73865682106927, parameters k is 4.04666066757543 and b is -5.69421598086941\n",
      "Iteration 63, the loss is 5.634020796023929, parameters k is 4.086776374785859 and b is -5.688625501830227\n",
      "Iteration 64, the loss is 5.544940092512515, parameters k is 4.123613413688368 and b is -5.6835504288551375\n",
      "Iteration 65, the loss is 5.471094727303719, parameters k is 4.157440486022738 and b is -5.678948520668828\n",
      "Iteration 66, the loss is 5.411991322048745, parameters k is 4.188504272184625 and b is -5.674780997862923\n",
      "Iteration 67, the loss is 5.36269662883622, parameters k is 4.217031235976048 and b is -5.671012259180059\n",
      "Iteration 68, the loss is 5.321038783759273, parameters k is 4.243229281448277 and b is -5.667609621049781\n",
      "Iteration 69, the loss is 5.288211663767175, parameters k is 4.267289273958816 and b is -5.664543078470675\n",
      "Iteration 70, the loss is 5.261015853872193, parameters k is 4.289386436570772 and b is -5.661785085489311\n",
      "Iteration 71, the loss is 5.238923058155474, parameters k is 4.309681632010862 and b is -5.6593103536699365\n",
      "Iteration 72, the loss is 5.222442642605896, parameters k is 4.328322539565068 and b is -5.657095667080523\n",
      "Iteration 73, the loss is 5.208901300420881, parameters k is 4.345444735522277 and b is -5.655119712441541\n",
      "Iteration 74, the loss is 5.198902253445179, parameters k is 4.361172685070588 and b is -5.653362923194837\n",
      "Iteration 75, the loss is 5.191041384487848, parameters k is 4.375620652903153 and b is -5.651807336351774\n",
      "Iteration 76, the loss is 5.185079705021547, parameters k is 4.388893539195687 and b is -5.650436461073332\n",
      "Iteration 77, the loss is 5.181367257980971, parameters k is 4.401087647071758 and b is -5.649235158020675\n",
      "Iteration 78, the loss is 5.178902712750386, parameters k is 4.412291387170782 and b is -5.648189528593485\n",
      "Iteration 79, the loss is 5.177726985519652, parameters k is 4.422585924473416 and b is -5.647286813245736\n",
      "Iteration 80, the loss is 5.1774758894051915, parameters k is 4.432045772116638 and b is -5.6465152981349505\n",
      "Iteration 81, the loss is 5.178741516272357, parameters k is 4.440739336542948 and b is -5.645864229421981\n",
      "Iteration 82, the loss is 5.18046943967928, parameters k is 4.4487294179720855 and b is -5.6453237345943235\n",
      "Iteration 83, the loss is 5.182409550102357, parameters k is 4.4560736698567815 and b is -5.644884750237335\n",
      "Iteration 84, the loss is 5.184361634160732, parameters k is 4.462825020684002 and b is -5.644538955724948\n",
      "Iteration 85, the loss is 5.186470042674139, parameters k is 4.469032061207634 and b is -5.644278712344726\n",
      "Iteration 86, the loss is 5.188621355002018, parameters k is 4.474739399945679 and b is -5.644097007411902\n",
      "Iteration 87, the loss is 5.190649643384276, parameters k is 4.479987989542803 and b is -5.643987402963529\n",
      "Iteration 88, the loss is 5.192729791784107, parameters k is 4.484815426385985 and b is -5.643943988657388\n",
      "Iteration 89, the loss is 5.194764278136856, parameters k is 4.489256225665281 and b is -5.643961338531034\n",
      "Iteration 90, the loss is 5.196629595882356, parameters k is 4.493342073892086 and b is -5.644034471304649\n",
      "Iteration 91, the loss is 5.198447309367402, parameters k is 4.497102060722373 and b is -5.644158813937252\n",
      "Iteration 92, the loss is 5.200187732771747, parameters k is 4.500562891780941 and b is -5.644330168169649\n",
      "Iteration 93, the loss is 5.201783088365331, parameters k is 4.503749084043746 and b is -5.64454467980934\n",
      "Iteration 94, the loss is 5.203319316644672, parameters k is 4.506683145207743 and b is -5.644798810532671\n",
      "Iteration 95, the loss is 5.204829122378079, parameters k is 4.509385738360546 and b is -5.645089311997927\n",
      "Iteration 96, the loss is 5.206377628368236, parameters k is 4.511875833154654 and b is -5.645413202079978\n",
      "Iteration 97, the loss is 5.207829831937124, parameters k is 4.514170844592249 and b is -5.645767743052607\n",
      "Iteration 98, the loss is 5.209160548852898, parameters k is 4.516286760435948 and b is -5.646150421558891\n",
      "Iteration 99, the loss is 5.210390048114028, parameters k is 4.518238258177653 and b is -5.646558930223107\n",
      "Iteration 100, the loss is 5.211586327374857, parameters k is 4.520038812421261 and b is -5.646991150769623\n",
      "Iteration 101, the loss is 5.212694999519756, parameters k is 4.521700793464878 and b is -5.647445138525278\n",
      "Iteration 102, the loss is 5.213767337422113, parameters k is 4.523235557803755 and b is -5.647919108191856\n",
      "Iteration 103, the loss is 5.21474925612619, parameters k is 4.524653531216102 and b is -5.648411420784583\n",
      "Iteration 104, the loss is 5.215648165962396, parameters k is 4.525964285039631 and b is -5.648920571641058\n",
      "Iteration 105, the loss is 5.216470869950438, parameters k is 4.5271766061968854 and b is -5.649445179412927\n",
      "Iteration 106, the loss is 5.217223613571257, parameters k is 4.528298561481675 and b is -5.649983975959719\n",
      "Iteration 107, the loss is 5.217928339578873, parameters k is 4.529337556576938 and b is -5.650535797070945\n",
      "Iteration 108, the loss is 5.2185803296309325, parameters k is 4.530300390235822 and b is -5.6510995739485566\n",
      "Iteration 109, the loss is 5.2191763545506475, parameters k is 4.53119330402237 and b is -5.651674325387456\n",
      "Iteration 110, the loss is 5.219721000999037, parameters k is 4.532022027975734 and b is -5.652259150596854\n",
      "Iteration 111, the loss is 5.220218479739148, parameters k is 4.532791822531993 and b is -5.652853222609943\n",
      "Iteration 112, the loss is 5.220683720808988, parameters k is 4.533507517010287 and b is -5.653455782233685\n",
      "Iteration 113, the loss is 5.221127236841354, parameters k is 4.534173544944832 and b is -5.654066132494438\n",
      "Iteration 114, the loss is 5.22153187919764, parameters k is 4.534793976521319 and b is -5.65468363353879\n",
      "Iteration 115, the loss is 5.221900833815217, parameters k is 4.535372548354994 and b is -5.655307697952294\n",
      "Iteration 116, the loss is 5.222237025529244, parameters k is 4.535912690828294 and b is -5.655937786461854\n",
      "Iteration 117, the loss is 5.222543139471162, parameters k is 4.536417553188033 and b is -5.656573403990318\n",
      "Iteration 118, the loss is 5.222821640713542, parameters k is 4.5368900265857635 and b is -5.65721409603442\n",
      "Iteration 119, the loss is 5.223074792304911, parameters k is 4.537332765229865 and b is -5.657859445339558\n",
      "Iteration 120, the loss is 5.22330467182655, parameters k is 4.537748205804134 and b is -5.658509068847101\n",
      "Iteration 121, the loss is 5.223513186592387, parameters k is 4.53813858529492 and b is -5.659162614891867\n",
      "Iteration 122, the loss is 5.223702087603215, parameters k is 4.538505957357252 and b is -5.659819760629286\n",
      "Iteration 123, the loss is 5.22387298235722, parameters k is 4.538852207339683 and b is -5.660480209673423\n",
      "Iteration 124, the loss is 5.224027346610748, parameters k is 4.539179066077782 and b is -5.661143689928564\n",
      "Iteration 125, the loss is 5.224166535175095, parameters k is 4.5394881225571835 and b is -5.661809951598525\n",
      "Iteration 126, the loss is 5.224291791828539, parameters k is 4.53978083553884 and b is -5.662478765359102\n",
      "Iteration 127, the loss is 5.224404258416015, parameters k is 4.540058544231538 and b is -5.663149920680299\n",
      "Iteration 128, the loss is 5.224504983202988, parameters k is 4.540322478089746 and b is -5.663823224286053\n",
      "Iteration 129, the loss is 5.224594928544777, parameters k is 4.540573765808484 and b is -5.664498498740198\n",
      "Iteration 130, the loss is 5.224674977927209, parameters k is 4.540813443581029 and b is -5.66517558114831\n",
      "Iteration 131, the loss is 5.2247459424304115, parameters k is 4.541042462679853 and b is -5.665854321965949\n",
      "Iteration 132, the loss is 5.224808566662754, parameters k is 4.541261696416277 and b is -5.666534583904561\n",
      "Iteration 133, the loss is 5.22486353420851, parameters k is 4.5414719465297475 and b is -5.667216240927052\n",
      "Iteration 134, the loss is 5.22491147262911, parameters k is 4.541673949053477 and b is -5.667899177325685\n",
      "Iteration 135, the loss is 5.224952958054375, parameters k is 4.541868379699374 and b is -5.668583286875535\n",
      "Iteration 136, the loss is 5.224989262910333, parameters k is 4.542055858801653 and b is -5.669268472057331\n",
      "Iteration 137, the loss is 5.2250211917196605, parameters k is 4.54223695585529 and b is -5.669954643343989\n",
      "Iteration 138, the loss is 5.225047978033199, parameters k is 4.542412193682531 and b is -5.670641718545617\n",
      "Iteration 139, the loss is 5.225070043362883, parameters k is 4.542582052257939 and b is -5.671329622208191\n",
      "Iteration 140, the loss is 5.225087774675805, parameters k is 4.542746972219956 and b is -5.672018285061528\n",
      "Iteration 141, the loss is 5.225101527225323, parameters k is 4.542907358094685 and b is -5.672707643512487\n",
      "Iteration 142, the loss is 5.225111627150127, parameters k is 4.5430635812554545 and b is -5.673397639179711\n",
      "Iteration 143, the loss is 5.225118373860368, parameters k is 4.543215982639847 and b is -5.674088218466498\n",
      "Iteration 144, the loss is 5.225122042228139, parameters k is 4.543364875244046 and b is -5.674779332168672\n",
      "Iteration 145, the loss is 5.225122884598491, parameters k is 4.543510546412762 and b is -5.675470935114603\n",
      "Iteration 146, the loss is 5.225121132635659, parameters k is 4.54365325994149 and b is -5.676162985834715\n",
      "Iteration 147, the loss is 5.225116999017901, parameters k is 4.543793258006474 and b is -5.676855446258087\n",
      "Iteration 148, the loss is 5.225110678993536, parameters k is 4.543930762936508 and b is -5.677548281433919\n",
      "Iteration 149, the loss is 5.22510235180936, parameters k is 4.544065978839522 and b is -5.678241459275823\n",
      "Iteration 150, the loss is 5.225092182022082, parameters k is 4.544199093095866 and b is -5.67893495032707\n",
      "Iteration 151, the loss is 5.225080320702221, parameters k is 4.544330277729215 and b is -5.679628727545081\n",
      "Iteration 152, the loss is 5.2250669065394, parameters k is 4.544459690665116 and b is -5.680322766103571\n",
      "Iteration 153, the loss is 5.225052066856929, parameters k is 4.544587476886397 and b is -5.681017043210919\n",
      "Iteration 154, the loss is 5.22503591854344, parameters k is 4.54471376949388 and b is -5.681711537943412\n",
      "Iteration 155, the loss is 5.225018568907977, parameters k is 4.544838690680168 and b is -5.682406231092169\n",
      "Iteration 156, the loss is 5.225000116465113, parameters k is 4.544962352623623 and b is -5.683101105022594\n",
      "Iteration 157, the loss is 5.224980651655715, parameters k is 4.545084858309079 and b is -5.683796143545362\n",
      "Iteration 158, the loss is 5.224960257508579, parameters k is 4.545206302281295 and b is -5.684491331797973\n",
      "Iteration 159, the loss is 5.224939010247915, parameters k is 4.545326771336657 and b is -5.685186656136006\n",
      "Iteration 160, the loss is 5.22491697985101, parameters k is 4.545446345158191 and b is -5.685882104033299\n",
      "Iteration 161, the loss is 5.224894230560207, parameters k is 4.545565096898539 and b is -5.686577663990298\n",
      "Iteration 162, the loss is 5.224870821352853, parameters k is 4.5456830937151524 and b is -5.687273325449925\n",
      "Iteration 163, the loss is 5.224846806372866, parameters k is 4.545800397261626 and b is -5.687969078720336\n",
      "Iteration 164, the loss is 5.224822235326792, parameters k is 4.545917064138763 and b is -5.68866491490401\n",
      "Iteration 165, the loss is 5.224797153847494, parameters k is 4.546033146308676 and b is -5.689360825832652\n",
      "Iteration 166, the loss is 5.22477160382805, parameters k is 4.546148691474949 and b is -5.69005680400743\n",
      "Iteration 167, the loss is 5.224745623728159, parameters k is 4.546263743431642 and b is -5.690752842544109\n",
      "Iteration 168, the loss is 5.224719248855594, parameters k is 4.546378342383696 and b is -5.691448935122682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 169, the loss is 5.224692511624483, parameters k is 4.546492525241078 and b is -5.692145075941127\n",
      "Iteration 170, the loss is 5.224665441792477, parameters k is 4.546606325888817 and b is -5.692841259672959\n",
      "Iteration 171, the loss is 5.224638066678442, parameters k is 4.546719775434914 and b is -5.6935374814282556\n",
      "Iteration 172, the loss is 5.224610411362321, parameters k is 4.546832902437931 and b is -5.694233736717879\n",
      "Iteration 173, the loss is 5.224582498868664, parameters k is 4.54694573311593 and b is -5.69493002142063\n",
      "Iteration 174, the loss is 5.224554350335044, parameters k is 4.5470582915382876 and b is -5.695626331753093\n",
      "Iteration 175, the loss is 5.224525985166694, parameters k is 4.547170599801788 and b is -5.696322664241955\n",
      "Iteration 176, the loss is 5.224497421178532, parameters k is 4.547282678192289 and b is -5.697019015698588\n",
      "Iteration 177, the loss is 5.224468674725412, parameters k is 4.547394545333134 and b is -5.697715383195723\n",
      "Iteration 178, the loss is 5.224439760821885, parameters k is 4.547506218321402 and b is -5.698411764046023\n",
      "Iteration 179, the loss is 5.224410693251943, parameters k is 4.547617712852993 and b is -5.699108155782427\n",
      "Iteration 180, the loss is 5.224381484669938, parameters k is 4.547729043337463 and b is -5.6998045561400925\n",
      "Iteration 181, the loss is 5.224352146693145, parameters k is 4.54784022300344 and b is -5.700500963039825\n",
      "Iteration 182, the loss is 5.224322689986728, parameters k is 4.5479512639954125 and b is -5.701197374572861\n",
      "Iteration 183, the loss is 5.224293124341794, parameters k is 4.548062177462579 and b is -5.701893788986905\n",
      "Iteration 184, the loss is 5.224263458747047, parameters k is 4.548172973640412 and b is -5.7025902046733\n",
      "Iteration 185, the loss is 5.2242337014545015, parameters k is 4.548283661925547 and b is -5.703286620155262\n",
      "Iteration 186, the loss is 5.224203860039857, parameters k is 4.5483942509445265 and b is -5.703983034077065\n",
      "Iteration 187, the loss is 5.224173941458, parameters k is 4.548504748616914 and b is -5.704679445194127\n",
      "Iteration 188, the loss is 5.224143952093802, parameters k is 4.548615162213232 and b is -5.7053758523638995\n",
      "Iteration 189, the loss is 5.224113897808864, parameters k is 4.548725498408157 and b is -5.7060722545375\n",
      "Iteration 190, the loss is 5.2240837839844, parameters k is 4.5488357633293495 and b is -5.706768650752044\n",
      "Iteration 191, the loss is 5.2240536155606145, parameters k is 4.548945962602286 and b is -5.707465040123589\n",
      "Iteration 192, the loss is 5.224023397072823, parameters k is 4.549056101391413 and b is -5.708161421840671\n",
      "Iteration 193, the loss is 5.223993132684687, parameters k is 4.549166184437933 and b is -5.708857795158362\n",
      "Iteration 194, the loss is 5.223962826218584, parameters k is 4.549276216094491 and b is -5.709554159392817\n",
      "Iteration 195, the loss is 5.223932481183655, parameters k is 4.549386200357016 and b is -5.710250513916268\n",
      "Iteration 196, the loss is 5.223902100801461, parameters k is 4.549496140893958 and b is -5.710946858152429\n",
      "Iteration 197, the loss is 5.223871688029515, parameters k is 4.549606041073129 and b is -5.711643191572276\n",
      "Iteration 198, the loss is 5.223841245582961, parameters k is 4.549715903986333 and b is -5.712339513690173\n",
      "Iteration 199, the loss is 5.22381077595443, parameters k is 4.549825732471996 and b is -5.713035824060319\n"
     ]
    }
   ],
   "source": [
    "#参数初始化\n",
    "k = random.random() * 200 - 100  # -100 100\n",
    "b = random.random() * 200 - 100  # -100 100\n",
    "learning_rate = 1e-3\n",
    "iteration_num = 200 \n",
    "losses = []\n",
    "for i in range(iteration_num):\n",
    "    price_use_current_parameters = [price(r, k, b) for r in X_rm]  # \\hat{y}\n",
    "    #计算loss\n",
    "    current_loss = loss(y, price_use_current_parameters)\n",
    "    losses.append(current_loss)\n",
    "    print(\"Iteration {}, the loss is {}, parameters k is {} and b is {}\".format(i,current_loss,k,b))\n",
    "    #更新梯度\n",
    "    k_gradient = partial_derivative_k(X_rm, y, price_use_current_parameters)\n",
    "    b_gradient = partial_derivative_b(y, price_use_current_parameters)\n",
    "    k = k + (-1 * k_gradient) * learning_rate\n",
    "    b = b + (-1 * b_gradient) * learning_rate\n",
    "best_k = k\n",
    "best_b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26c2ecb2dd8>]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(iteration_num)),losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x26c2ed21860>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "price_use_best_parameters = [price(r, best_k, best_b) for r in X_rm]\n",
    "\n",
    "plt.scatter(X_rm,y)\n",
    "plt.scatter(X_rm,price_use_current_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "+ 是否将Loss改成了“绝对值”(3')\n",
    "+ 是否完成了偏导的重新定义(5')\n",
    "+ 新的模型Loss是否能够收敛 (11’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
